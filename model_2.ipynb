{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Second Model\n",
    "Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# setup data \n",
    "image_list = []\n",
    "    # -3 means back one directory\n",
    "# filename/shape/type/label\n",
    "for filepath in glob.glob('images/*/*/*.png', recursive=True):\n",
    "     filename = filepath.split(\"\\\\\")[-1]\n",
    "     sign_shape = filepath.split(\"\\\\\")[-2]\n",
    "     sign_type = filepath.split(\"\\\\\")[-3]\n",
    "     \n",
    "     image_list.append((filepath,sign_shape,sign_type))\n",
    "     \n",
    "data = pd.DataFrame(data=image_list, columns=['image_path','sign_type', 'sign_shape'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dataframes for training and validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "r_inx = np.random.choice(100, 4)\n",
    "rand_data = data.loc[r_inx,'image_path']\n",
    "\n",
    "\n",
    "d = {'rightofway':0, 'stop':1, 'bicycle':2,\n",
    "     'limitedtraffic':3, 'noentry':4, 'noparking':5,\n",
    "     'roundabout':6, 'speed':7,'trafficdirective':8,\n",
    "     'traveldirection':9,'continue':10,'crossing':11,\n",
    "     'laneend':12, 'parking':13, 'giveway':14, 'warning':15}\n",
    "data['type_num'] = data['sign_type'].map(d, na_action='ignore')\n",
    "\n",
    "train, validate, test = np.split(data.sample(frac=1), [int(.6*len(data)), int(.8*len(data))])\n",
    "\n",
    "\n",
    "N_train_images = train.shape[0]\n",
    "N_val_images = validate.shape[0]\n",
    "N_test_images = test.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, data_format='channels_last',\n",
    "                                   rotation_range=20, width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   horizontal_flip=True,fill_mode='nearest')\n",
    "                                \n",
    "                                   \n",
    "val_datagen = ImageDataGenerator(rescale=1./255, data_format='channels_last',\n",
    "                                   rotation_range=20, width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   horizontal_flip=True,fill_mode='nearest')\n",
    "test_datagen = ImageDataGenerator(rescale=1./255, data_format='channels_last')\n",
    "\n",
    "\n",
    "batch_size = 300\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train,\n",
    "        directory='./',\n",
    "        x_col=\"image_path\",\n",
    "        y_col=\"sign_type\",\n",
    "        target_size=(28, 28),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = val_datagen.flow_from_dataframe(\n",
    "        dataframe=validate,\n",
    "        directory='./',\n",
    "        x_col=\"image_path\",\n",
    "        y_col=\"sign_type\",\n",
    "        target_size=(28, 28),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "        dataframe=test,\n",
    "        directory='./',\n",
    "        x_col=\"image_path\",\n",
    "        y_col=\"sign_type\",\n",
    "        target_size=(28, 28),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Lambda\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Input\n",
    "from tensorflow.keras import regularizers, optimizers\n",
    "from tensorflow.keras.metrics import categorical_accuracy, sparse_categorical_crossentropy, sparse_categorical_accuracy\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras import regularizers, optimizers\n",
    "from keras.layers import GaussianNoise\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model = Sequential()\n",
    "chanDim = -1\n",
    "\n",
    "# input\n",
    "model.add(Input(shape=(28, 28, 3)))\n",
    "model.add(Lambda(lambda x: tf.expand_dims(x[:,:,:,0], -1, name=None))) \n",
    "# this is a workaround. Dataloader automatically read one channel image as 3 channel \n",
    "#and we use Lambda layer to revert this back. Lambda layer can be used for operation \n",
    "#that does not involve trainianble weights\n",
    "\n",
    "model.add(Conv2D(8, (5, 5), padding=\"same\",kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# first set of (CONV => RELU => CONV => RELU) * 2 => POOL\n",
    "model.add(Conv2D(16, (3, 3), padding=\"same\",kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(16, (3, 3), padding=\"same\",kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# second set of (CONV => RELU => CONV => RELU) * 2 => POOL\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\",kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\",kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "# first set of FC => RELU layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "# second set of FC => RELU layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=[categorical_accuracy])\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def calculate_losses(model_in, data_generator_in, N_images, batch_size_):\n",
    "    loss_hold = []\n",
    "    acc_hold = []\n",
    "    batches = 0\n",
    "\n",
    "    # iterate over each batch\n",
    "    for x,y in data_generator_in:\n",
    "        loss, acc = model_in.evaluate(x, y, verbose=0)\n",
    "        loss_hold.append(loss)\n",
    "        acc_hold.append(acc)\n",
    "        batches += 1\n",
    "        if batches >= N_images / batch_size_:\n",
    "            # we need to break the loop by hand because the generator loops indefinitely\n",
    "            break\n",
    "\n",
    "    return np.mean(loss_hold), np.mean(acc_hold)\n",
    "\n",
    "\n",
    "def train_model_two(model_, num_epoch=30, verbose=False):\n",
    "    res = []\n",
    "    for e in range(num_epoch):\n",
    "        # print('Epoch', e)\n",
    "        batches = 0\n",
    "\n",
    "        loss_ = []\n",
    "        acc_ = []\n",
    "\n",
    "         # iterate over each batch\n",
    "        for x,y in train_generator:\n",
    "            loss, acc = model_.train_on_batch(x, y) # Update weights and return train loss, acc per batch\n",
    "            loss_.append(loss)\n",
    "            acc_.append(acc)\n",
    "            batches += 1\n",
    "            if batches >= N_train_images / batch_size:\n",
    "                # we need to break the loop by hand because\n",
    "                # the generator loops indefinitely\n",
    "                break\n",
    "        loss_ = np.mean(loss_)\n",
    "        acc_ = np.mean(acc_)\n",
    "\n",
    "        loss, acc = calculate_losses(model_, validation_generator, N_val_images, batch_size)\n",
    "        if verbose:\n",
    "            print(\"Training epoch {}: Loss = {}, Accuracy = {}\".format(e, loss_, acc_))\n",
    "            print(\"Validation epoch {}: Loss = {}, Accuracy = {}\".format(e, loss, acc))\n",
    "\n",
    "        res.append((e, loss_, acc_, loss, acc))\n",
    "\n",
    "    model_.save('model.h5')\n",
    "    print('Model saved')\n",
    "\n",
    "    return np.asarray(res)\n",
    "\n",
    "\n",
    "\n",
    "res_two = train_model_two(model, num_epoch=30, verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "def plot_results(res):\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(res[:,0], res[:,1], 'r-')\n",
    "    plt.plot(res[:,0], res[:,3], 'b-')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.ylim([0, np.max([5., np.max(res[:,1]), np.max(res[:,3])])])\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(res[:,0], res[:,2], 'r-')\n",
    "    plt.plot(res[:,0], res[:,4], 'b-')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([0, np.max([1., np.max(res[:,2]), np.max(res[:,4])])])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Predict Model 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_results(res_two)\n",
    "\n",
    "\n",
    "\n",
    "pred = model.predict(test_generator)\n",
    "print(np.argmax(pred[0]))\n",
    "\n",
    "predicted_class_indices=np.argmax(pred,axis=1)\n",
    "\n",
    "\n",
    "labels = train_generator.filenames\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "\n",
    "filenames=test_generator.filenames\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":predictions})\n",
    "print(results)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}